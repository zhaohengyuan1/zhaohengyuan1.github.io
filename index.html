<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hengyuan</title>
</head>

<link rel="stylesheet" href="./font-awesome-4.7.0/css/font-awesome.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
<!-- <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css"> -->

<style>
    body {
        margin: 0;
        padding: 0;
        background-color: #010409;
        color: #c9d1d9;
    }
    
    h2 {
        /* margin: 0; */
        padding: 0;
    }
    
    .myname {
        padding: 0 0 0 0;
        margin: 0.5em 0 0.5em 0;
    }
    
    a {
        text-decoration: none;
        color: #1C86EE;
    }
    
    a:hover {
        color: orange;
        text-decoration: underline;
    }
    
    .main {
        padding: 1em;
        width: 1000px;
        height: 100%;
        margin: 0 auto;
        /* background-color: ghostwhite; */
        /* border-color: #c9d1c9; */
        /* font-size: 18px; */
        /* font-family: "Open Sans", "Helvetica Neue", Helvetica; */
    }
    
    .icons {
        font-size: 22px;
    }
    
    .title {
        /* padding: 0 0 0 0.6em; */
        margin: 0.5em 0 1em 0;
    }
    
    .self_link {
        /* padding: 0 0 0 0.6em; */
        margin: 0 0 1em 0;
        /* border: 1px solid rgba(240, 246, 252, 0.4); */
        /* border-radius: 6px; */
    }
    
    .h2_title {
        padding: 0 0 0.2em 0;
        /* border: 1px solid #30363d;
        border-radius: 6px; */
        border-bottom: 2px solid #30363d;
    }
    
    .news_list {
        padding: 0 0 0 1.3em;
    }
    
    .pub_img {
        /* width: 60%; */
        width: 260px;
        height: 150px;
        /* border: 1px solid #30363d; */
        border-radius: 6px;
    }
    /* .pub_tr {
        padding: 0 0 2em 0;
    } */
    
    .paper_info {
        padding: 0 0 0 0.5em;
    }
    
    .paper_title {
        font-size: 18px;
        color: #1C86EE;
        margin: 0 0 0.2em 0;
        /* color: orange; */
    }
    
    .paper_author {
        font-size: 14px;
        margin: 0 0 0.2em 0;
    }
    
    .paper_pub {
        font-size: 14px;
        margin: 0 0 0.2em 0;
    }
    /* .paper_link {
        color: orange;
    } */
</style>


<body>
    <div class="page">
        <div class="main">
            <h2 class="myname">Henguan Zhao (赵恒远)</h2>
            <div class="title">
                <div>Research Assistant at Shenzhen Institutes of Advanced Technology (SIAT)</div>
                <div>Email: zhaohengyuan99@gmail.com</div>
                <div>Live in Shenzhen, China</div>
            </div>

            <div class="self_link">
                <span>Links: </span>
                <span>
                    <a href="https://github.com/zhaohengyuan1"><i class="fa fa-github icons" aria-hidden="true"></i> GitHub</a>
                </span>
                <span>/</span>
                <span>       
                    <a href="https://scholar.google.com/citations?user=QLSk-6IAAAAJ&hl=zh-CN"><i class="ai ai-google-scholar icons"></i> Google Scholar</a>
                </span>
                <span>/</span>
                <span>
                    <a href="./My_academic_CV.pdf"><i class="ai ai-cv icons"></i></a>
                </span>
            </div>

            <h2 class="h2_title">Experience</h2>
            <div>
                <strong>2020/12-now:</strong> I join the Vision Technology (VIS), Baidu Inc. as a research intern and work with
                <a href="https://whwu95.github.io/">Wenhao Wu</a>.
            </div>
            <div>
                <strong>2019/09-now:</strong> I am a research assistant at SIAT and supervised by Prof.
                <a href="http://www.cs.cityu.edu.hk/~cssamk/research_group/index.html">Chao Dong</a>.
            </div>
            <div>
                <strong>2016/09-2020/06:</strong> I was a undergraduate student at Nanjing University of Posts and Telecommunications, Nanjing, China.
            </div>

            <h2 class="h2_title">News</h2>

            <ul class="news_list">
                <li>
                    <span>
                        [03/2021] One paper accepted by CVPR, 2021.
                    </span>
                </li>
                <li>
                    <span>
                        [12/2020] Join VIS, Baidu, mentored by Wenhao WU.
                    </span>
                </li>
                <li>
                    <span>
                        [08/2020] One paper accepted by ECCV Workshop, 2020.
                    </span>
                </li>
                <li>
                    <span>
                        [05/2020] Participate the Efficient Super-Resoluton Challenge of AIM 2020 (ECCV Workshop). We got fouth places () and lowest parameters.
                    </span>
                </li>
                <li>
                    <span>
                        [09/2019] Join MMLAB at SIAT, supervised by Yu Qiao and Chao Dong.
                    </span>
                </li>
                <li>
                    <span>
                        [08/2019] One paper accepted by ICCV Workshop, 2019.
                    </span>
                </li>
            </ul>

            <h2 class="h2_title">Publications</h2>
            <table>

                <tr class="pub_tr">
                    <td><img src="./publication_imgs/ClassSR2021.png" alt="" class="pub_img"></td>
                    <td class="paper_info" valign="top">
                        <a href="" class="paper_title">ClassSR: A General Framework to Accelerate Super-Resolution Networks by Data Characteristic</a>
                        <div class="paper_author">Xiangtao Kong, <b style="text-decoration: underline;">Hengyuan Zhao</b>, Yu Qiao, Chao Dong</div>
                        <div class="paper_pub"> <i>Computer Vision and Pattern Recognition (CVPR)</i>, 2021</div>
                        <div>
                            <span>
                                <a class="paper_link" href="https://arxiv.org/pdf/2103.04039.pdf">Paper(arxiv)</a>
                            </span>
                            <span>|</span>
                            <span>
                                <a class="paper_link" href="https://github.com/Xiangtaokong/ClassSR">Codes</a>
                            </span>
                            <span>|</span>
                            <span>
                                <a class="paper_link" href="">BibTex</a>
                            </span>
                        </div>
                    </td>
                </tr>
                <tr class="pub_tr">
                    <td><img src="./publication_imgs/CSRNet_pami.png" alt="" class="pub_img"></td>
                    <td class="paper_info" valign="top">
                        <a href="" class="paper_title">Very Lightweight Photo Retouching Network with Conditional Sequential Modulation</a>
                        <div class="paper_author">Yihao Liu, Jingwen He, Xiangyu Chen, Zhengwen Zhang, <b style="text-decoration: underline;">Hengyuan Zhao</b>, Chao Dong, Yu Qiao</div>
                        <!-- <div class="paper_pub">European Conference on Computer Vision Workshops (ECCVW), 2020</div> -->
                        <div>
                            <span>
                                <a class="paper_link" href="https://arxiv.org/pdf/2104.06279.pdf">Paper(arxiv)</a>
                            </span>
                            <span>|</span>
                            <span>
                                <a class="paper_link" href="https://github.com/hejingwenhejingwen/CSRNet">Codes</a>
                            </span>
                            <span>|</span>
                            <span>
                                <a class="paper_link" href="">BibTex</a>
                            </span>
                        </div>
                    </td>
                </tr>
                <tr class="pub_tr">
                    <td><img src="./publication_imgs/pan2020.png" alt="" class="pub_img"></td>
                    <td class="paper_info" valign="top">
                        <a href="" class="paper_title">Efficient Image Super-Resolution Using Pixel Attention</a>
                        <div class="paper_author"><b style="text-decoration: underline;">Hengyuan Zhao</b>, Xiangtao Kong, Jingwen He, Yu Qiao, Chao Dong</div>
                        <div class="paper_pub"> <i>European Conference on Computer Vision Workshops (ECCVW)</i>, 2020</div>
                        <div>
                            <span>
                                <a class="paper_link" href="https://arxiv.org/pdf/2010.01073.pdf">Paper(arxiv)</a>
                            </span>
                            <span>|</span>
                            <span>
                                <a class="paper_link" href="https://github.com/zhaohengyuan1/PAN">Codes</a>
                            </span>
                            <span>|</span>
                            <span>
                                <a class="paper_link" href="">BibTex</a>
                            </span>
                        </div>
                    </td>
                </tr>
            </table>

        </div>
    </div>
</body>

</html>